<h1 align="center">
    <img alt="YouTube Safe Kids" src="../../static/img/logo.svg" width="200" />
</h1>

<h3 align="center">
  YouTube Safe Kids: Busca Segura de V√≠deos com Intelig√™ncia Artificial
</h3>

<p align="center">Uma plataforma de filtragem inteligente para conte√∫do infantil no YouTube</p>

<p align="center">
  <img alt="GitHub language count" src="https://img.shields.io/badge/languages-3-brightgreen">
  <img alt="License" src="https://img.shields.io/badge/license-MIT-brightgreen">
  <img alt="Made with Python" src="https://img.shields.io/badge/made%20with-Python-blue">
  <img alt="Project Status" src="https://img.shields.io/badge/status-em%20desenvolvimento-yellow">
</p>

## üìë Sobre o Projeto

O YouTube Safe Kids √© uma plataforma avan√ßada que utiliza m√∫ltiplas t√©cnicas de Intelig√™ncia Artificial para filtrar e recomendar apenas conte√∫do adequado e seguro para crian√ßas. O sistema implementa diversos filtros baseados em diferentes tecnologias, desde Processamento de Linguagem Natural (PLN) at√© Vis√£o Computacional e Machine Learning, garantindo uma experi√™ncia segura e educativa.

## üõ†Ô∏è Tecnologias Utilizadas

O sistema utiliza uma combina√ß√£o de diferentes tecnologias de IA para an√°lise de conte√∫do:

### Filtros e Tecnologias

| Filtro | Tecnologia | Descri√ß√£o |
|--------|------------|-----------|
| Sentimento | PLN | An√°lise do tom emocional do conte√∫do |
| Toxicidade | PLN | Detec√ß√£o de conte√∫do t√≥xico ou ofensivo |
| Educacional | PLN | Avalia√ß√£o do valor educacional |
| Linguagem | PLN | Identifica√ß√£o de linguagem impr√≥pria |
| Faixa Et√°ria | Machine Learning | Classifica√ß√£o por idade apropriada |
| Diversidade | Vis√£o Computacional | An√°lise de diversidade visual |
| Dura√ß√£o | Metadados | Filtro baseado na dura√ß√£o do v√≠deo |
| Engajamento | Metadados | An√°lise de m√©tricas de engajamento |
| Interatividade | Machine Learning | Avalia√ß√£o do n√≠vel de interatividade |
| Conte√∫do Sens√≠vel | Vis√£o Computacional | Detec√ß√£o de conte√∫do visual impr√≥prio |

## üß† M√≥dulo de Processamento de Linguagem Natural (PLN)

Este m√≥dulo cont√©m implementa√ß√µes de modelos PLN baseados no BERTimbau para an√°lise de conte√∫do em portugu√™s brasileiro. Os modelos s√£o utilizados em filtros avan√ßados para garantir que apenas conte√∫do adequado e educacional seja recomendado para crian√ßas.

### üìÅ Estrutura

```
app/nlp/
‚îú‚îÄ‚îÄ datasets/             # Conjuntos de dados para treinar os modelos
‚îú‚îÄ‚îÄ evaluation/           # Scripts para avaliar os modelos
‚îú‚îÄ‚îÄ models/               # Implementa√ß√µes dos modelos e modelos treinados
‚îÇ   ‚îú‚îÄ‚îÄ bertimbau_base.py         # Classe base para os modelos BERTimbau
‚îÇ   ‚îú‚îÄ‚îÄ bertimbau_sentiment.py    # Modelo para an√°lise de sentimento
‚îÇ   ‚îú‚îÄ‚îÄ bertimbau_toxicity.py     # Modelo para detec√ß√£o de toxicidade
‚îÇ   ‚îú‚îÄ‚îÄ bertimbau_educational.py  # Modelo para classifica√ß√£o educacional
‚îÇ   ‚îî‚îÄ‚îÄ bertimbau_language.py     # Modelo para detec√ß√£o de linguagem impr√≥pria
‚îú‚îÄ‚îÄ training/             # Scripts para treinamento dos modelos
‚îÇ   ‚îî‚îÄ‚îÄ train_model.py            # Script principal de treinamento
‚îî‚îÄ‚îÄ utils/                # Utilit√°rios para processamento de texto e dados
```

### ü§ñ Modelos PLN Dispon√≠veis

#### 1. An√°lise de Sentimento (SentimentModel)
- **Descri√ß√£o**: Classifica textos em sentimentos positivos, negativos ou neutros.
- **Classes**: 0=Negativo, 1=Neutro, 2=Positivo
- **Arquivo**: `models/bertimbau_sentiment.py`

#### 2. Detec√ß√£o de Toxicidade (ToxicityModel)
- **Descri√ß√£o**: Identifica conte√∫do t√≥xico, ofensivo ou inadequado para crian√ßas.
- **Classes**: 0=N√£o T√≥xico, 1=Levemente T√≥xico, 2=Moderadamente T√≥xico, 3=Altamente T√≥xico
- **Arquivo**: `models/bertimbau_toxicity.py`

#### 3. Classifica√ß√£o Educacional (EducationalModel)
- **Descri√ß√£o**: Avalia o valor educacional de textos, classificando-os em diferentes n√≠veis.
- **Classes**: 0=N√£o Educacional, 1=Potencialmente Educacional, 2=Educacional, 3=Altamente Educacional
- **Arquivo**: `models/bertimbau_educational.py`

#### 4. Detec√ß√£o de Linguagem Impr√≥pria (LanguageModel)
- **Descri√ß√£o**: Identifica linguagem inadequada para crian√ßas, incluindo palavr√µes e termos inapropriados.
- **Classes**: 0=Apropriado, 1=Question√°vel, 2=Inapropriado, 3=Altamente Inapropriado
- **Arquivo**: `models/bertimbau_language.py`

## üîç Uso dos Modelos PLN

### Prepara√ß√£o de Datasets

1. Colete dados etiquetados para cada tarefa e salve como CSV ou Excel na pasta `datasets/`.
2. Os datasets devem ter pelo menos duas colunas: texto e r√≥tulo.

### Treinamento dos Modelos ‚Äî Grid Search com Cross-Validation

O treinamento utiliza **Grid Search com K-Fold Cross-Validation** (K=5) para sele√ß√£o de hiperpar√¢metros, com **oversampling no conjunto de treino** e **Focal Loss** para lidar com desbalanceamento de classes.

#### ‚≠ê Modo Recomendado para o Artigo: `--mode optimized`

O modo `optimized` utiliza **Successive Halving** (Jamieson & Talwalkar, 2016) em 2 est√°gios para reduzir drasticamente o tempo de treinamento sem perder rigor cient√≠fico:

| Est√°gio | Descri√ß√£o | Configs | Folds | √âpocas | Treinos |
|---------|-----------|---------|-------|--------|---------|
| 1 ‚Äî Triagem | Avalia√ß√£o r√°pida de todas as configura√ß√µes | 12 | 2 | 3 (fixo) | 24 |
| 2 ‚Äî Avalia√ß√£o | Valida√ß√£o completa das melhores configs | Top 6 | 5 | originais | 30 |
| **Total** | | | | | **~54** |

```bash
# Recomendado para o artigo (~3-4 dias)
python -m app.nlp.training.train_toxicity_gridsearch --mode optimized
```

Grid de hiperpar√¢metros (baseado em Devlin et al., 2019):
- **epochs**: [3, 5]
- **batch_size**: [8, 16]
- **learning_rate**: [2e-5, 3e-5, 5e-5]
- **max_length**: [128]

#### Modo de Valida√ß√£o R√°pida: `--mode fast`

Executa apenas 1 configura√ß√£o √ó 5 folds para verificar se o pipeline funciona corretamente. √ötil para testes antes de iniciar o treinamento completo.

```bash
# Valida√ß√£o r√°pida do pipeline (~4h)
python -m app.nlp.training.train_toxicity_gridsearch --mode fast
```

#### Modo Completo: `--mode full`

Grid Search exaustivo com 72 configura√ß√µes √ó 5 folds = 360 treinos. **N√£o recomendado** ‚Äî tempo estimado de ~56 dias.

```bash
# N√ÉO RECOMENDADO (uso excepcional)
python -m app.nlp.training.train_toxicity_gridsearch --mode full
```

#### Op√ß√£o de Pr√©-processamento

Adicione `--preprocess` para aplicar limpeza de texto e lematiza√ß√£o antes da tokeniza√ß√£o do BERT:

```bash
python -m app.nlp.training.train_toxicity_gridsearch --mode optimized --preprocess
```

#### Sa√≠da do Treinamento

Ao final do treinamento, o script:
1. Salva os resultados detalhados em JSON em `evaluation/results/toxicity_gridsearch/`
2. Treina automaticamente o **modelo final** com a melhor configura√ß√£o encontrada
3. Salva o modelo final em `models/trained/` para uso no `evaluate_toxicity.py`

#### üñ•Ô∏è Execu√ß√£o no Servidor (Debian via SSH)

Para rodar o treinamento em segundo plano e manter o processo ativo ap√≥s fechar o SSH:

```bash
# Rodar em segundo plano com log (dentro da pasta brasnam-2026)
nohup python -m app.nlp.training.train_toxicity_gridsearch --mode optimized > treinamento.log 2>&1 &
```

Comandos de monitoramento:

```bash
# Acompanhar o progresso em tempo real
tail -f treinamento.log

# Verificar se o processo ainda est√° rodando
ps aux | grep train_toxicity

# Parar o treinamento (se necess√°rio)
kill <PID>
```

Alternativa com `screen` (permite reconectar √† sess√£o):

```bash
screen -S treinamento                                                    # Criar sess√£o
python -m app.nlp.training.train_toxicity_gridsearch --mode optimized     # Executar
# Ctrl+A, depois D ‚Üí desanexar a sess√£o
screen -r treinamento                                                    # Reconectar depois
```

### Uso dos Modelos Treinados

Exemplo de como utilizar um modelo treinado:

```python
from app.nlp.models.bertimbau_sentiment import SentimentModel

# Carregar modelo treinado
model = SentimentModel.from_pretrained("app/nlp/models/bertimbau_sentiment")

# Fazer predi√ß√£o
result = model.predict("Este v√≠deo √© muito divertido e educativo!")
print(f"Sentimento: {result['label']} (confian√ßa: {result['confidence']:.2f})")

# Predi√ß√£o em lote
texts = ["Este v√≠deo √© assustador", "Aprendi muito com esta aula", "N√£o gostei deste desenho"]
results = model.predict(texts)
for i, res in enumerate(results["results"]):
    print(f"Texto {i+1}: {res['label']} (confian√ßa: {res['confidence']:.2f})")
```

## üîÑ Integra√ß√£o com os Filtros

Os modelos de IA s√£o utilizados pelos filtros correspondentes no sistema:

- **Modelos PLN**:
  - `SentimentModel` √© usado pelo `SentimentFilter`
  - `ToxicityModel` √© usado pelo `ToxicityFilter`
  - `EducationalModel` √© usado pelo `EducationalFilter`
  - `LanguageModel` √© usado pelo `LanguageFilter`

- **Modelos de Machine Learning**:
  - Classificadores de idade s√£o usados pelo `AgeRatingFilter`
  - An√°lise de comportamento √© usada pelo `InteractivityFilter`

- **Modelos de Vis√£o Computacional**:
  - An√°lise de imagem √© usada pelo `DiversityFilter`
  - Detec√ß√£o de conte√∫do impr√≥prio √© usada pelo `SensitiveFilter`

- **An√°lise de Metadados**:
  - Processamento de dura√ß√£o √© usado pelo `DurationFilter`
  - An√°lise de engajamento √© usada pelo `EngagementFilter`

## üé• Integra√ß√£o com YouTube API

O sistema utiliza a YouTube Data API v3 para buscar e analisar v√≠deos. A integra√ß√£o √© feita atrav√©s do m√≥dulo `app/core/youtube.py` que √© utilizado pelo endpoint de busca em `app/api/endpoints/videos.py`.

### Fluxo de Busca e An√°lise

1. **Busca de V√≠deos**: O endpoint `/search/` recebe uma consulta e par√¢metros de filtros
2. **Chamada da API**: O `YouTubeAPI.search_videos()` busca v√≠deos usando a YouTube Data API
3. **Obten√ß√£o de Transcri√ß√µes**: Se filtros PLN est√£o habilitados, o sistema obt√©m transcri√ß√µes dos v√≠deos
4. **Processamento**: Cada v√≠deo √© processado pelos filtros habilitados
5. **Classifica√ß√£o**: Os v√≠deos s√£o ordenados por score final e retornados

### M√©todo de Pesquisa (`search_videos`)

```python
async def search_videos(self, query: str, max_results: int = None, 
                       video_duration: str = None, 
                       nlp_filters_enabled: List[str] = None) -> List[Dict[str, Any]]
```

**Par√¢metros:**
- `query`: Termo de busca
- `max_results`: N√∫mero m√°ximo de resultados (padr√£o: `MAX_SEARCH_RESULTS`)
- `video_duration`: Filtro de dura√ß√£o ('short', 'medium', 'long')
- `nlp_filters_enabled`: Lista de filtros PLN que requerem transcri√ß√£o

**Funcionalidades:**
- Busca com `safeSearch: strict` para conte√∫do apropriado para crian√ßas
- Filtragem por dura√ß√£o quando especificada
- Obten√ß√£o de metadados detalhados (visualiza√ß√µes, likes, coment√°rios)
- Extra√ß√£o de transcri√ß√µes quando filtros PLN est√£o ativos

### Sistema de Transcri√ß√£o

O sistema de transcri√ß√£o √© controlado pela configura√ß√£o `ENABLE_VIDEO_TRANSCRIPTION` e funciona da seguinte forma:

#### M√©todo `get_video_sentences`

Extrai tr√™s frases representativas de cada v√≠deo:
- **In√≠cio**: Primeiros 10% da transcri√ß√£o
- **Meio**: Segmentos de 40% a 60% da transcri√ß√£o  
- **Fim**: √öltimos 10% da transcri√ß√£o

```python
async def get_video_sentences(self, video_id: str) -> Dict[str, str]:
    """
    Retorna: {"start": "frase_inicio", "middle": "frase_meio", "end": "frase_fim"}
    """
```

**Processo de Extra√ß√£o:**
1. Busca transcri√ß√µes em portugu√™s (manual tem prioridade sobre auto-gerada)
2. Divide a transcri√ß√£o em segmentos temporais
3. Extrai a primeira frase completa de cada segmento
4. Limpa e formata o texto para an√°lise PLN

**Tratamento de Erros:**
- Retorna frases vazias se `ENABLE_VIDEO_TRANSCRIPTION = False`
- Trata casos de v√≠deos sem transcri√ß√£o dispon√≠vel
- Gerencia erros de v√≠deos indispon√≠veis ou privados

### Utiliza√ß√£o pelos Filtros PLN

Os filtros de PLN utilizam as frases extra√≠das para an√°lise:

```python
# No filtro educacional, por exemplo
sentences = video_data.get('sentences', {})
combined_text = f"{video_data['title']} {video_data['description']} {sentences['start']} {sentences['middle']} {sentences['end']}"
```

**Filtros que Utilizam Transcri√ß√£o:**
- **An√°lise de Sentimentos**: Analisa o tom emocional do conte√∫do falado
- **Detec√ß√£o de Toxicidade**: Identifica linguagem t√≥xica ou ofensiva
- **Classifica√ß√£o Educacional**: Avalia valor educacional baseado no conte√∫do falado
- **Detec√ß√£o de Linguagem Impr√≥pria**: Detecta palavr√µes ou linguagem inadequada

### Configura√ß√µes da YouTube API

As seguintes vari√°veis de configura√ß√£o controlam o comportamento da integra√ß√£o:

#### `YOUTUBE_API_KEY`
- **Tipo**: String
- **Descri√ß√£o**: Chave de API do Google para acessar a YouTube Data API v3
- **Obrigat√≥rio**: Sim
- **Configura√ß√£o**: Definida via vari√°vel de ambiente ou arquivo `.env`

#### `MAX_SEARCH_RESULTS`
- **Tipo**: Integer
- **Padr√£o**: 8
- **Descri√ß√£o**: N√∫mero m√°ximo de v√≠deos retornados por busca
- **Impacto**: Afeta performance e custos da API

#### `ENABLE_VIDEO_TRANSCRIPTION`
- **Tipo**: Boolean  
- **Padr√£o**: False
- **Descri√ß√£o**: Habilita/desabilita a obten√ß√£o de transcri√ß√µes de v√≠deos
- **Impacto**: 
  - `True`: Filtros PLN funcionam com an√°lise completa (t√≠tulo + descri√ß√£o + transcri√ß√£o)
  - `False`: Filtros PLN funcionam apenas com t√≠tulo e descri√ß√£o

### Exemplo de Uso Completo

```python
from app.core.youtube import YouTubeAPI
from app.core.config import get_settings

settings = get_settings()
youtube_api = YouTubeAPI(settings.YOUTUBE_API_KEY)

# Busca com filtros PLN habilitados
nlp_filters = ["An√°lise de Sentimentos", "Detec√ß√£o de Toxicidade"]
videos = await youtube_api.search_videos(
    query="desenhos educativos para crian√ßas",
    max_results=10,
    video_duration="medium",
    nlp_filters_enabled=nlp_filters
)

# Cada v√≠deo retornado cont√©m:
for video in videos:
    print(f"T√≠tulo: {video['title']}")
    print(f"Dura√ß√£o: {video['duration_seconds']} segundos")
    print(f"Frases: {video['sentences']}")
```

## ‚öôÔ∏è Vari√°veis de Configura√ß√£o

O sistema utiliza tr√™s vari√°veis de configura√ß√£o principais definidas em `app/core/config.py`:

### YOUTUBE_API_KEY
- **Descri√ß√£o**: Chave de API do YouTube Data API v3
- **Tipo**: String
- **Obrigat√≥rio**: Sim
- **Fun√ß√£o**: Permite acesso √† API do YouTube para buscar informa√ß√µes de v√≠deos, incluindo metadados, estat√≠sticas e detalhes dos canais
- **Como obter**: 
  1. Acesse o [Google Cloud Console](https://console.cloud.google.com/)
  2. Crie um projeto ou selecione um existente
  3. Ative a YouTube Data API v3
  4. Gere uma chave de API
- **Configura√ß√£o**: Defina no arquivo `.env` como `YOUTUBE_API_KEY=sua_chave_aqui`

### MAX_SEARCH_RESULTS
- **Descri√ß√£o**: N√∫mero m√°ximo de v√≠deos retornados por busca
- **Tipo**: Integer
- **Padr√£o**: 50
- **Fun√ß√£o**: Limita a quantidade de resultados processados por consulta, otimizando performance e custos de API
- **Recomenda√ß√µes**: 
  - Para testes: 10-20 v√≠deos
  - Para uso normal: 50 v√≠deos
  - Para an√°lises extensas: at√© 100 v√≠deos (cuidado com limites de API)

### ENABLE_VIDEO_TRANSCRIPTION
- **Descri√ß√£o**: Habilita ou desabilita a captura de transcri√ß√µes de v√≠deos
- **Tipo**: Boolean
- **Padr√£o**: True
- **Fun√ß√£o**: Controla se o sistema deve tentar obter transcri√ß√µes autom√°ticas ou manuais dos v√≠deos para an√°lise de conte√∫do
- **Impacto**: 
  - `True`: Permite an√°lise completa de conte√∫do textual dos v√≠deos
  - `False`: An√°lise baseada apenas em metadados (t√≠tulo, descri√ß√£o, tags)
- **Considera√ß√µes**: Desabilitar pode melhorar a performance, mas reduz a precis√£o dos filtros de PLN

## ‚öôÔ∏è Requisitos T√©cnicos

Este m√≥dulo depende dos seguintes pacotes:
- transformers
- torch
- pandas
- numpy
- scikit-learn
- datasets
- opencv-python (para os filtros de vis√£o computacional)
- fastapi (para a API)

Instale os requisitos com:
```bash
pip install transformers torch pandas numpy scikit-learn datasets opencv-python fastapi
```

## üöÄ Como Executar

1. Clone o reposit√≥rio:
```bash
git clone https://github.com/seu-usuario/YouTubeSafeKids-Python.git
```

2. Acesse o diret√≥rio do projeto:
```bash
cd YouTubeSafeKids-Python
```

3. Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```

4. Inicie o servidor:
```bash
uvicorn app.main:app --reload
```

O aplicativo estar√° dispon√≠vel em [http://localhost:8000](http://localhost:8000).

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo LICENSE para mais detalhes.